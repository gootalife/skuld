hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/DFSck.java
  private static final String USAGE = "Usage: hdfs fsck <path> "
      + "[-list-corruptfileblocks | "
      + "[-move | -delete | -openforwrite] "
      + "[-files [-blocks [-locations | -racks | -replicaDetails]]]] "
      + "[-includeSnapshots] "
      + "[-storagepolicies] [-blockId <blk_Id>]\n"
      + "\t<path>\tstart checking from this path\n"
      + "\t-move\tmove corrupted files to /lost+found\n"
      + "\t-delete\tdelete corrupted files\n"
      + "\t-files -blocks -locations\tprint out locations for every block\n"
      + "\t-files -blocks -racks" 
      + "\tprint out network topology for data-node locations\n"
      + "\t-files -blocks -replicaDetails\tprint out each replica details \n"
      + "\t-storagepolicies\tprint out storage policy summary for the blocks\n"
      + "\t-blockId\tprint out which file this blockId belongs to, locations"
      + " (nodes, racks) of this block, and other diagnostics info"
      + " (under replicated, corrupted or not, etc)\n\n"
      + "Please Note:\n"
      + "\t1. By default fsck ignores files opened for write, "
      + "use -openforwrite to report such files. They are usually "

